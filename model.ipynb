{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import sys\n",
    "# 绘图\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(PNet, self).__init__()\n",
    "        self.conv1 = conv2d(10, 3, 1, 'valid', name='conv1')\n",
    "        self.prelu1 = tf.keras.layers.PReLU(name='prelu1',shared_axes=[1,2])\n",
    "        self.pool1 = pool2d(name='pool1')\n",
    "\n",
    "        self.conv2 = conv2d(16, 3, 1, 'valid', name='conv2')\n",
    "        self.prelu2 = tf.keras.layers.PReLU(name='prelu2',shared_axes=[1,2])\n",
    "\n",
    "        self.conv3 = conv2d(32, 3, 1, 'valid', name='conv3')\n",
    "        self.prelu3 = tf.keras.layers.PReLU(name='prelu3',shared_axes=[1,2])\n",
    "\n",
    "        self.conv4_1 = conv2d(\n",
    "            2, 1, 1, 'same', activation='softmax', name='conv4_1')\n",
    "        self.conv4_2 = conv2d(4, 1, 1, 'same', name='conv4_2')\n",
    "\n",
    "    def call(self, input_):\n",
    "        out = self.conv1(input_)\n",
    "        out = self.prelu1(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.prelu2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.prelu3(out)\n",
    "\n",
    "        prob = self.conv4_1(out)\n",
    "        loc = self.conv4_2(out)\n",
    "        return prob, loc\n",
    "    def model_variable_initialize(self):\n",
    "        image = tf.random_normal((1, 12, 12, 3))\n",
    "        with tf.name_scope('PNet'):\n",
    "            self.call(image)\n",
    "        print(\"Completed\")\n",
    "\n",
    "def conv2d(filter, ksize=3, stride=1, padding='same', dilation=1, activation=None, name=\"conv2d\"):\n",
    "    ksize = [ksize] * 2\n",
    "    strides = [stride] * 2\n",
    "    dilation = [dilation] * 2\n",
    "    return tf.keras.layers.Conv2D(filters=filter, kernel_size=ksize, strides=strides, padding=padding, dilation_rate=dilation, activation=activation, name=name)\n",
    "\n",
    "\n",
    "def pool2d(ksize=2, stride=2, padding='same', name='pool2d'):\n",
    "    ksize = [ksize] * 2\n",
    "    strides = [stride]*2\n",
    "    return tf.keras.layers.MaxPool2D(pool_size=ksize, strides=strides, padding=padding, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PNet()\n",
    "model.model_variable_initialize()\n",
    "model_vars = model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('other_02.jpg')\n",
    "\"\"\"\n",
    "image = (image-127.5)/128\n",
    "image = np.expand_dims(image,0)\n",
    "model = PNet()\n",
    "model(image)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.load(r\"F:\\Script\\models\\face recognition\\det1.npy\",encoding='latin1').item()\n",
    "to = {'prelu1': 'PReLU1', 'prelu2': 'PReLU2', 'prelu3': 'PReLU3', 'conv1': 'conv1',\n",
    "      'conv2': 'conv2', 'conv3': 'conv3', 'conv4_1': 'conv4-1', 'conv4_2': 'conv4-2'}\n",
    "too = {'kernel':'weights','bias':'biases','alpha':'alpha'}\n",
    "for var in model_vars:\n",
    "    name = var.name\n",
    "    name0 = name.split('/')[1]\n",
    "    name1 = name.split('/')[-1]\n",
    "    name1 = name1.split(':')[0]\n",
    "    dual_name0 = to[name0]\n",
    "    dual_name1 = too[name1]\n",
    "    value = weights[dual_name0][dual_name1]\n",
    "    if name1 == \"alpha\":\n",
    "        value = np.expand_dims(value,0)\n",
    "        value = np.expand_dims(value,0)\n",
    "    print(name0,name1,var.shape,value.shape)\n",
    "    tf.assign(var,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./checkpoints/pnet/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob,loc = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(tf.argmax(prob,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, scales = generate_samples_from_image(image, 30)\n",
    "img = images[0]\n",
    "scale = scales[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bboxes = []\n",
    "total_bboxes_ref = []\n",
    "for img, scale in zip(images, scales):\n",
    "    prob, loc = model(img)\n",
    "    original_bboxes = generate_original_boxes(loc.numpy(), scale)\n",
    "    filter_mask = tf.argmax(prob, axis=-1)\n",
    "    bboxes_tf = tf.boolean_mask(original_bboxes, filter_mask)\n",
    "    bboxes_ref_tf = tf.boolean_mask(loc, filter_mask)\n",
    "    local_bboxes, local_bboxes_ref = bboxes_nms(\n",
    "        bboxes_tf.numpy(), bboxes_ref_tf.numpy(), 0.6)\n",
    "    total_bboxes.append(local_bboxes)\n",
    "    total_bboxes_ref.append(local_bboxes_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bboxes = np.concatenate(total_bboxes)\n",
    "total_bboxes_ref = np.concatenate(total_bboxes_ref)\n",
    "bboxes, bboxes_ref = bboxes_nms(total_bboxes, total_bboxes_ref, 0.7)\n",
    "bboxes = bboxes_reg(bboxes, bboxes_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w, _ = image.shape\n",
    "bboxes_cp, pad_bboxes = bboxes_clip(bboxes, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = crop_image(image,bboxes_cp, pad_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "keep_bboxes = np.ones((bboxes.shape[0], 1), dtype=np.bool)\n",
    "overlap = bboxes_iou(bboxes[i], bboxes[(i+1):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_overlap = overlap < 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_bboxes[(i+1):] = np.logical_and(keep_bboxes[(i+1):],np.expand_dims(keep_overlap,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_overlap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(RNet, self).__init__()\n",
    "        self.conv1 = conv2d(28, 3, 1, 'valid', name='conv1')\n",
    "        self.prelu1 = tf.keras.layers.PReLU(name='prelu1', shared_axes=[1, 2])\n",
    "        self.pool1 = pool2d(3, 2, name='pool1')\n",
    "\n",
    "        self.conv2 = conv2d(48, 3, 1, 'valid', name='conv2')\n",
    "        self.prelu2 = tf.keras.layers.PReLU(name='prelu2', shared_axes=[1, 2])\n",
    "        self.pool2 = pool2d(3, 2, 'valid', name='pool2')\n",
    "\n",
    "        self.conv3 = conv2d(64, 2, 1, 'valid', name='conv3')\n",
    "        self.prelu3 = tf.keras.layers.PReLU(name='prelu3', shared_axes=[1, 2])\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(128, name='fc1')\n",
    "        self.prelu4 = tf.keras.layers.PReLU(name='prelu4')\n",
    "\n",
    "        self.fc2_1 = tf.keras.layers.Dense(\n",
    "            2, activation='softmax', name='fc2_1')\n",
    "        self.fc2_2 = tf.keras.layers.Dense(4, name='fc2_2')\n",
    "\n",
    "    def call(self, input_):\n",
    "        out = self.conv1(input_)\n",
    "        out = self.prelu1(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.prelu2(out)\n",
    "        out = self.pool2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.prelu3(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.prelu4(out)\n",
    "\n",
    "        prob = self.fc2_1(out)\n",
    "        loc = self.fc2_2(out)\n",
    "        return prob, loc\n",
    "\n",
    "    def model_variable_initialize(self):\n",
    "        image = tf.random_normal((1, 24, 24, 3))\n",
    "        with tf.name_scope('RNet'):\n",
    "            self.call(image)\n",
    "        print(\"Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_variable_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vars = model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in model_vars:\n",
    "    print(var.name,var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.load(r\"F:\\Script\\models\\face recognition\\det2.npy\",encoding='latin1').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = {'prelu1': 'prelu1', 'prelu2': 'prelu2', 'prelu3': 'prelu3','prelu4': 'prelu4', 'conv1': 'conv1',\n",
    "      'conv2': 'conv2', 'conv3': 'conv3', 'fc1': 'conv4', 'fc2_1': 'conv5-1', 'fc2_2': 'conv5-2'}\n",
    "too = {'kernel':'weights','bias':'biases','alpha':'alpha'}\n",
    "for var in model_vars:\n",
    "    name = var.name\n",
    "    name0 = name.split('/')[1]\n",
    "    name1 = name.split('/')[-1]\n",
    "    name1 = name1.split(':')[0]\n",
    "    dual_name0 = to[name0]\n",
    "    dual_name1 = too[name1]\n",
    "    value = weights[dual_name0][dual_name1]\n",
    "    if name1 == \"alpha\" and name0 != 'prelu4':\n",
    "        value = np.expand_dims(value,0)\n",
    "        value = np.expand_dims(value,0)\n",
    "    print(name0,name1,var.shape,value.shape)\n",
    "    tf.assign(var,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./checkpoints/rnet/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ONet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ONet, self).__init__()\n",
    "        self.conv1 = conv2d(32, 3, 1, 'valid', name='conv1')\n",
    "        self.prelu1 = tf.keras.layers.PReLU(name='prelu1', shared_axes=[1, 2])\n",
    "        self.pool1 = pool2d(3, 2, name='pool1')\n",
    "\n",
    "        self.conv2 = conv2d(64, 3, 1, 'valid', name='conv2')\n",
    "        self.prelu2 = tf.keras.layers.PReLU(name='prelu2', shared_axes=[1, 2])\n",
    "        self.pool2 = pool2d(3, 2, 'valid', name='pool2')\n",
    "\n",
    "        self.conv3 = conv2d(64, 3, 1, 'valid', name='conv3')\n",
    "        self.prelu3 = tf.keras.layers.PReLU(name='prelu3', shared_axes=[1, 2])\n",
    "        self.pool3 = pool2d(2, 2, name='pool3')\n",
    "\n",
    "        self.conv4 = conv2d(128, 2, 1, 'valid', name='conv4')\n",
    "        self.prelu4 = tf.keras.layers.PReLU(name='prelu4', shared_axes=[1, 2])\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(256, name='fc1')\n",
    "        self.prelu5 = tf.keras.layers.PReLU(name='prelu5')\n",
    "\n",
    "        self.fc2_1 = tf.keras.layers.Dense(\n",
    "            2, activation='softmax', name='fc2_1')\n",
    "        self.fc2_2 = tf.keras.layers.Dense(4, name='fc2_2')\n",
    "        self.fc2_3 = tf.keras.layers.Dense(10, name='fc2_3')\n",
    "\n",
    "    def call(self, input_):\n",
    "        out = self.conv1(input_)\n",
    "        out = self.prelu1(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.prelu2(out)\n",
    "        out = self.pool2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.prelu3(out)\n",
    "        out = self.pool3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.prelu4(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.prelu5(out)\n",
    "\n",
    "        prob = self.fc2_1(out)\n",
    "        loc = self.fc2_2(out)\n",
    "        landmark = self.fc2_3(out)\n",
    "        return prob, loc, landmark\n",
    "\n",
    "    def model_variable_initialize(self):\n",
    "        image = tf.random_normal((1, 48, 48, 3))\n",
    "        with tf.name_scope('ONet'):\n",
    "            self.call(image)\n",
    "        print(\"Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ONet()\n",
    "model.model_variable_initialize()\n",
    "model_vars = model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in model_vars:\n",
    "    print(var.name,var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.load(r\"F:\\Script\\models\\face recognition\\det3.npy\",encoding='latin1').item()\n",
    "sorted(weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = {'prelu1': 'prelu1', 'prelu2': 'prelu2', 'prelu3': 'prelu3','prelu4': 'prelu4', 'prelu5': 'prelu5', 'conv1': 'conv1',\n",
    "      'conv2': 'conv2', 'conv3': 'conv3', 'conv4': 'conv4', 'fc1': 'conv5', 'fc2_1': 'conv6-1', 'fc2_2': 'conv6-2', 'fc2_3': 'conv6-3'}\n",
    "too = {'kernel':'weights','bias':'biases','alpha':'alpha'}\n",
    "for var in model_vars:\n",
    "    name = var.name\n",
    "    name0 = name.split('/')[1]\n",
    "    name1 = name.split('/')[-1]\n",
    "    name1 = name1.split(':')[0]\n",
    "    dual_name0 = to[name0]\n",
    "    dual_name1 = too[name1]\n",
    "    value = weights[dual_name0][dual_name1]\n",
    "    if name1 == \"alpha\" and name0 != 'prelu5':\n",
    "        value = np.expand_dims(value,0)\n",
    "        value = np.expand_dims(value,0)\n",
    "    print(name0,name1,var.shape,value.shape)\n",
    "    tf.assign(var,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./checkpoints/onet/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, size=(12, 12)):\n",
    "    return cv2.resize(image, size)\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess a image\"\"\"\n",
    "    image_cp = np.copy(image)#.astype(np.float32)\n",
    "    # regularize the image\n",
    "    image_regular = (image_cp-127.5)/128\n",
    "    # expand the batch_size dim\n",
    "    image_expanded = np.expand_dims(image_regular, axis=0)\n",
    "    return image_expanded\n",
    "def cal_scales(minsize, factor=0.709, size=(12, 12)):\n",
    "    minlen = np.min(size)\n",
    "    s = 12.0/minsize\n",
    "    minlen *= (s*factor)\n",
    "    scales = [s]\n",
    "    while (minlen >= 12):\n",
    "        scales.append(s * np.power(factor, len(scales)))\n",
    "        minlen *= factor\n",
    "    return scales\n",
    "\n",
    "\n",
    "def generate_samples_from_image(image, minsize=30, factor=0.709):\n",
    "    height, weight, _ = image.shape\n",
    "    scales = cal_scales(minsize, factor, size=(weight, height))\n",
    "    images = []\n",
    "    for scale in scales:\n",
    "        w, h = int(np.ceil(weight * scale)), int(np.ceil(height * scale))\n",
    "        images.append(preprocess_image(resize_image(image, size=(h, w))))\n",
    "    return images, scales\n",
    "\n",
    "\n",
    "def generate_original_boxes(bbox_reg, scale):\n",
    "    # bboxes shape of (h,w,4)\n",
    "    bboxes = np.zeros_like(bbox_reg, dtype=np.float32)\n",
    "    _,h, w, _ = np.shape(bboxes)\n",
    "    x, y = np.mgrid[0:w, 0:h]\n",
    "    bboxes[0, :, :, 0] = x * 2 / scale\n",
    "    bboxes[0, :, :, 1] = y * 2 / scale\n",
    "    bboxes[0, :, :, 2] = (x * 2+12) / scale\n",
    "    bboxes[0, :, :, 3] = (y * 2+12) / scale\n",
    "    return tf.convert_to_tensor(bboxes)\n",
    "\n",
    "\n",
    "def bboxes_iou(bboxes1, bboxes2):\n",
    "    \"\"\"Computing iou between bboxes1 and bboxes2.\n",
    "    Note: bboxes1 and bboxes2 can be multi-dimensional, but should broacastable.\n",
    "    \"\"\"\n",
    "    bboxes1 = np.transpose(bboxes1)\n",
    "    bboxes2 = np.transpose(bboxes2)\n",
    "    # Intersection bbox and volume.\n",
    "    int_ymin = np.maximum(bboxes1[0], bboxes2[0])\n",
    "    int_xmin = np.maximum(bboxes1[1], bboxes2[1])\n",
    "    int_ymax = np.minimum(bboxes1[2], bboxes2[2])\n",
    "    int_xmax = np.minimum(bboxes1[3], bboxes2[3])\n",
    "\n",
    "    int_h = np.maximum(int_ymax - int_ymin, 0.)\n",
    "    int_w = np.maximum(int_xmax - int_xmin, 0.)\n",
    "    int_vol = int_h * int_w\n",
    "    # Union volume.\n",
    "    vol1 = (bboxes1[2] - bboxes1[0]) * (bboxes1[3] - bboxes1[1])\n",
    "    vol2 = (bboxes2[2] - bboxes2[0]) * (bboxes2[3] - bboxes2[1])\n",
    "    iou = int_vol / (vol1 + vol2 - int_vol)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def bboxes_nms(bboxes, bboxes_ref, nms_threshold=0.5):\n",
    "    \"\"\"Apply non-maximum selection to bounding boxes.\n",
    "    \"\"\"\n",
    "    keep_bboxes = np.ones((bboxes.shape[0]), dtype=np.bool)\n",
    "    for i in range(bboxes.shape[0]-1):\n",
    "        if keep_bboxes[i]:\n",
    "            # Computer overlap with bboxes which are following.\n",
    "            overlap = bboxes_iou(bboxes[i], bboxes[(i+1):])\n",
    "            # Overlap threshold for keeping + checking part of the same class\n",
    "            keep_overlap = overlap < nms_threshold\n",
    "            keep_bboxes[(i+1):] = np.logical_and(keep_bboxes[(i+1):],\n",
    "                                                 keep_overlap)\n",
    "    idxes = np.where(keep_bboxes)\n",
    "    return bboxes[idxes], bboxes_ref[idxes]\n",
    "\n",
    "\n",
    "def bboxes_reg(bboxes, bboxes_ref):\n",
    "    \"\"\"boxes bounding regression.\n",
    "\n",
    "    Args:\n",
    "        bboxes ([array]): original boxes\n",
    "        bboxes_ref ([array]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [array]: [description]\n",
    "    \"\"\"\n",
    "    w = bboxes[:, 0] - bboxes[:, 2]\n",
    "    h = bboxes[:, 1] - bboxes[:, 3]\n",
    "    bboxes[:, 0] += bboxes_ref[:, 0] * w\n",
    "    bboxes[:, 1] += bboxes_ref[:, 1] * h\n",
    "    bboxes[:, 2] += bboxes_ref[:, 2] * w\n",
    "    bboxes[:, 3] += bboxes_ref[:, 3] * h\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def rec2square(bboxes):\n",
    "    \"\"\"Convert bbox to square.\"\"\"\n",
    "    h = bboxes[:, 3]-bboxes[:, 1]\n",
    "    w = bboxes[:, 2]-bboxes[:, 0]\n",
    "    l = np.maximum(w, h)\n",
    "    bboxes[:, 0] = bboxes[:, 0]+w*0.5-l*0.5\n",
    "    bboxes[:, 1] = bboxes[:, 1]+h*0.5-l*0.5\n",
    "    bboxes[:, 2:4] = bboxes[:, 0:2] + np.transpose(np.tile(l, (2, 1)))\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def bboxes_clip(bboxes, w, h):\n",
    "    \"\"\"Clip bounding boxes\n",
    "\n",
    "    Args:\n",
    "        bboxes ([array]): shape of (N, 4)\n",
    "        w ([int]): the width of input image\n",
    "        h ([int]): the heigh of input image\n",
    "\n",
    "    Returns:\n",
    "        [tuple of array]: return the position of cliped boxes and\n",
    "        padding for each axis\n",
    "    \"\"\"\n",
    "    bboxes_cp = bboxes.copy()\n",
    "    boxes_w = (bboxes[:, 2]-bboxes[:, 0]+1).astype(np.int32)\n",
    "    boxes_h = (bboxes[:, 3] - bboxes[:, 0] + 1).astype(np.int32)\n",
    "    bboxes_cp[:, 0] = np.maximum(bboxes[:, 0], 0)\n",
    "    bboxes_cp[:, 1] = np.maximum(bboxes[:, 1], 0)\n",
    "    bboxes_cp[:, 2] = np.minimum(bboxes[:, 2], w)\n",
    "    bboxes_cp[:, 3] = np.minimum(bboxes[:, 3], h)\n",
    "\n",
    "    pad_bboxes = np.zeros_like(bboxes, dtype=np.int32)\n",
    "    pad_bboxes[:, 0] = bboxes_cp[:, 0] - bboxes[:, 0]\n",
    "    pad_bboxes[:, 1] = bboxes_cp[:, 1] - bboxes[:, 1]\n",
    "    pad_bboxes[:, 2] = bboxes[:, 2] - bboxes_cp[:, 2]\n",
    "    pad_bboxes[:, 3] = bboxes[:, 3] - bboxes_cp[:, 3]\n",
    "    pad_bboxes[pad_bboxes < 0] = 0\n",
    "    return bboxes_cp.astype(np.int32), pad_bboxes\n",
    "\n",
    "\n",
    "def crop_image(image, bboxes, pad_bboxes, size=[24, 24]):\n",
    "    # example shape of [N,24,24,3]\n",
    "    shape = [bboxes.shape[0]] + size + [3]\n",
    "    images = np.zeros(shape)\n",
    "    for idx in range(bboxes.shape[0]):\n",
    "        x1, y1, x2, y2 = bboxes[idx]\n",
    "        padding = ((pad_bboxes[idx, 1], pad_bboxes[idx, 3]),\n",
    "                   (pad_bboxes[idx, 0], pad_bboxes[idx, 2]),\n",
    "                   (0,0))\n",
    "        temp_img = image[x1:x2, y1:y2]\n",
    "        temp_img = np.pad(\n",
    "            temp_img, padding, 'constant', constant_values=0)\n",
    "        images[idx] = resize_image(temp_img, size=tuple(size))\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
